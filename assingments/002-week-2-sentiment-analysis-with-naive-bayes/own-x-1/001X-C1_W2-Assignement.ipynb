{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords, twitter_samples\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mikael/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /Users/mikael/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"twitter_samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_positive_tweets = twitter_samples.strings(\"positive_tweets.json\")\n",
    "all_negative_tweets = twitter_samples.strings(\"negative_tweets.json\")\n",
    "\n",
    "assert len(all_positive_tweets) == len(all_negative_tweets)\n",
    "\n",
    "n = len(all_positive_tweets)\n",
    "\n",
    "TRAIN_PCT = 0.8\n",
    "TRAIN_N = int(n * TRAIN_PCT)\n",
    "\n",
    "train_x_pos = all_positive_tweets[:TRAIN_N]\n",
    "train_x_neg = all_negative_tweets[:TRAIN_N]\n",
    "train_x = train_x_pos + train_x_neg\n",
    "\n",
    "test_x_pos = all_positive_tweets[TRAIN_N:]\n",
    "test_x_neg = all_negative_tweets[TRAIN_N:]\n",
    "test_x = test_x_pos + test_x_neg\n",
    "\n",
    "train_y = np.append(np.ones(len(train_x_pos)), np.zeros(len(train_x_neg)))\n",
    "test_y = np.append(np.ones(len(test_x_pos)), np.zeros(len(test_x_neg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    \"\"\"\n",
    "    Preprocesses a tweet by removing unnecessary elements and applying stemming.\n",
    "\n",
    "    Parameters:\n",
    "    tweet (str): The input tweet to be processed.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of cleaned and stemmed words from the tweet.\n",
    "\n",
    "    Example:\n",
    "    >>> tweet = \"I love this movie! #amazing\"\n",
    "    >>> process_tweet(tweet)\n",
    "    ['love', 'movi', 'amaz']\n",
    "    \"\"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words(\"english\")\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r\"\\$\\w*\", \"\", tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r\"^RT[\\s]+\", \"\", tweet)\n",
    "    # remove hyperlinks\n",
    "    # tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    tweet = re.sub(r\"https?://[^\\s\\n\\r]+\", \"\", tweet)\n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r\"#\", \"\", tweet)\n",
    "    # tokenize tweets\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if (\n",
    "            word not in stopwords_english\n",
    "            and word not in string.punctuation  # remove stopwords\n",
    "        ):  # remove punctuation\n",
    "            # tweets_clean.append(word)\n",
    "            stem_word = stemmer.stem(word)  # stemming word\n",
    "            tweets_clean.append(stem_word)\n",
    "\n",
    "    return tweets_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the process tweet function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'great', 'day', ':)', 'good', 'morn']\n"
     ]
    }
   ],
   "source": [
    "custom_tweet = \"RT @Twitter @chapagain Hello There! Have a great day. :) #good #morning http://chapagain.com.np\"\n",
    "\n",
    "print(process_tweet(custom_tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create helper function that returns a dict with freqs of `(word, label)` in a dataset of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tweets(result, tweets, ys):\n",
    "    \"\"\"\n",
    "    Count the number of times a word appears in positive and negative tweets.\n",
    "\n",
    "    Parameters:\n",
    "    result (dict): A dictionary to store the count of words in positive and negative tweets.\n",
    "    tweets (list): A list of tweets.\n",
    "    ys (list): A list of labels corresponding to the sentiment of each tweet.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the count of words in positive and negative tweets.\n",
    "    \"\"\"\n",
    "    for tweet, label in zip(tweets, ys):\n",
    "        for word in process_tweet(tweet):\n",
    "            result[(word, label)] = result.get((word, label), 0) + 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the helper function `count_tweets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('happi', 1): 1, ('trick', 0): 1, ('sad', 0): 1, ('tire', 0): 2}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = [\"i am happy\", \"i am tricked\", \"i am sad\", \"i am tired\", \"i am tired\"]\n",
    "ys = [1, 0, 0, 0, 0]\n",
    "count_tweets({}, tweets, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(freq, train_x, train_y):\n",
    "    \"\"\"\n",
    "    Trains a Naive Bayes classifier using the given frequency dictionary and training data.\n",
    "\n",
    "    Args:\n",
    "        freq (dict): A dictionary containing the frequency of each word in the training data.\n",
    "        train_x (list): A list of training samples.\n",
    "        train_y (list): A list of corresponding labels for the training samples.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the log prior probability and the log likelihood dictionary.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If the length of train_x is not equal to the length of train_y.\n",
    "\n",
    "    \"\"\"\n",
    "    loglikelihood = {}\n",
    "    logprior = 0\n",
    "\n",
    "    assert len(train_x) == len(train_y)\n",
    "    D_pos = np.sum(train_y == 1)\n",
    "    D_neg = np.sum(train_y == 0)\n",
    "    logprior = np.log(D_pos / D_neg)\n",
    "\n",
    "    vocab = list(set(pair[0] for pair in freq.keys()))\n",
    "    V = len(vocab)\n",
    "    N_pos = np.sum([freq.get((word, 1), 0) for word in freq])\n",
    "    N_neg = np.sum([freq.get((word, 0), 0) for word in freq])\n",
    "\n",
    "    for word in vocab:\n",
    "        freq_pos = freq[(word, 1)] if (word, 1) in freq else 0\n",
    "        freq_neg = freq[(word, 0)] if (word, 0) in freq else 0\n",
    "        p_w_pos = (freq_pos + 1) / (N_pos + V)\n",
    "        p_w_neg = (freq_neg + 1) / (N_neg + V)\n",
    "        loglikelihood[word] = np.log(p_w_pos / p_w_neg)\n",
    "\n",
    "    return logprior, loglikelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "9161\n"
     ]
    }
   ],
   "source": [
    "freqs = count_tweets({}, train_x, train_y)\n",
    "logprior, loglikelihood = train_naive_bayes(freqs, train_x, train_y)\n",
    "print(logprior)\n",
    "print(len(loglikelihood))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_predict(tweet, logprior, loglikelihood):\n",
    "    \"\"\"\n",
    "    Predicts the sentiment of a given tweet using Naive Bayes algorithm.\n",
    "\n",
    "    Parameters:\n",
    "    tweet (str): The input tweet to be classified.\n",
    "    logprior (float): The logarithm of the prior probability.\n",
    "    loglikelihood (dict): A dictionary containing the logarithm of the likelihood probabilities for each word.\n",
    "\n",
    "    Returns:\n",
    "    float: The predicted sentiment score for the tweet.\n",
    "    \"\"\"\n",
    "    word_l = process_tweet(tweet)\n",
    "    p = logprior\n",
    "    for word in word_l:\n",
    "        if word in loglikelihood:\n",
    "            p += loglikelihood[word]\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected output is 1.5686159179138452\n",
      "The expected output is -0.15415067982725836\n"
     ]
    }
   ],
   "source": [
    "my_tweet = \"She smiled.\"\n",
    "p = naive_bayes_predict(my_tweet, logprior, loglikelihood)\n",
    "print(\"The expected output is\", p)\n",
    "\n",
    "my_tweet = \"He laughed.\"\n",
    "p = naive_bayes_predict(my_tweet, logprior, loglikelihood)\n",
    "print(\"The expected output is\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naive_bayes(\n",
    "    test_x, test_y, logprior, loglikelihood, naive_bayes_predict=naive_bayes_predict\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate the accuracy of the Naive Bayes classifier on the test data.\n",
    "\n",
    "    Args:\n",
    "        test_x (list): List of tweets to be classified.\n",
    "        test_y (list): List of true labels corresponding to the test tweets.\n",
    "        logprior (float): Logarithm of the prior probability.\n",
    "        loglikelihood (dict): Dictionary containing the logarithm of the likelihoods for each word.\n",
    "        naive_bayes_predict (function, optional): Function to predict the sentiment of a tweet using Naive Bayes.\n",
    "            Defaults to naive_bayes_predict.\n",
    "\n",
    "    Returns:\n",
    "        float: Accuracy of the Naive Bayes classifier on the test data.\n",
    "    \"\"\"\n",
    "    y_hats = []\n",
    "    for tweet in test_x:\n",
    "        y_hat_i = 0 if naive_bayes_predict(tweet, logprior, loglikelihood) < 0 else 1\n",
    "        y_hats.append(y_hat_i)\n",
    "\n",
    "    accuracy = np.sum(y_hats == test_y) / len(test_y)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy = 0.9945\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Naive Bayes accuracy = %0.4f\"\n",
    "    % (test_naive_bayes(test_x, test_y, logprior, loglikelihood))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am happy -> 2.15\n",
      "I am bad -> -1.30\n",
      "this movie should have been great. -> 2.14\n",
      "great -> 2.14\n",
      "great great -> 4.28\n",
      "great great great -> 6.42\n",
      "great great great great -> 8.56\n"
     ]
    }
   ],
   "source": [
    "for tweet in [\n",
    "    \"I am happy\",\n",
    "    \"I am bad\",\n",
    "    \"this movie should have been great.\",\n",
    "    \"great\",\n",
    "    \"great great\",\n",
    "    \"great great great\",\n",
    "    \"great great great great\",\n",
    "]:\n",
    "    # print( '%s -> %f' % (tweet, naive_bayes_predict(tweet, logprior, loglikelihood)))\n",
    "    p = naive_bayes_predict(tweet, logprior, loglikelihood)\n",
    "    #     print(f'{tweet} -> {p:.2f} ({p_category})')\n",
    "    print(f\"{tweet} -> {p:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter words by ratio of positive to negative counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup(freqs, word, label):\n",
    "    \"\"\"\n",
    "    Look up the frequency of a word in a given label.\n",
    "\n",
    "    Args:\n",
    "        freqs (dict): A dictionary containing word-frequency pairs.\n",
    "        word (str): The word to look up.\n",
    "        label (str): The label to search for.\n",
    "\n",
    "    Returns:\n",
    "        int: The frequency of the word in the given label.\n",
    "    \"\"\"\n",
    "    n = 0\n",
    "\n",
    "    pair = (word, label)\n",
    "    if pair in freqs:\n",
    "        n = freqs[pair]\n",
    "\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratio(freqs, word):\n",
    "    \"\"\"\n",
    "    Calculates the positive to negative ratio of a given word based on the frequency dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    freqs (dict): A dictionary containing the frequency of words in positive and negative classes.\n",
    "    word (str): The word for which the ratio needs to be calculated.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the positive count, negative count, and the ratio of positive to negative counts.\n",
    "    \"\"\"\n",
    "\n",
    "    pos_neg_ratio = {\"positive\": 0, \"negative\": 0, \"ratio\": 0.0}\n",
    "\n",
    "    pos_neg_ratio[\"positive\"] = lookup(freqs, word, 1)\n",
    "    pos_neg_ratio[\"negative\"] = lookup(freqs, word, 0)\n",
    "    pos_neg_ratio[\"ratio\"] = (pos_neg_ratio[\"positive\"] + 1) / (\n",
    "        pos_neg_ratio[\"negative\"] + 1\n",
    "    )\n",
    "\n",
    "    return pos_neg_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive': 162, 'negative': 18, 'ratio': 8.578947368421053}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ratio(freqs, \"happi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement get words by threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_by_threshold(freqs, label, threshold, get_ratio=get_ratio):\n",
    "    \"\"\"\n",
    "    Returns a list of words that are above or below a given threshold based on their positive-negative ratio.\n",
    "\n",
    "    Args:\n",
    "        freqs (dict): A dictionary containing word frequencies.\n",
    "        label (int): The label indicating whether to consider words above or below the threshold.\n",
    "                     1 for above threshold, 0 for below threshold.\n",
    "        threshold (float): The threshold value for the positive-negative ratio.\n",
    "        get_ratio (function, optional): A function to calculate the positive-negative ratio.\n",
    "                                        Defaults to get_ratio.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing words above or below the threshold along with their positive-negative ratio.\n",
    "\n",
    "    Example:\n",
    "        freqs = {('happy', 'positive'): 10, ('happy', 'negative'): 20, ('sad', 'positive'): 5, ('sad', 'negative'): 15}\n",
    "        label = 1\n",
    "        threshold = 0.5\n",
    "        get_words_by_threshold(freqs, label, threshold)\n",
    "        Output: {'happy': {'positive': 10, 'negative': 20, 'ratio': 0.5}}\n",
    "    \"\"\"\n",
    "    word_set = {}\n",
    "\n",
    "    for key in freqs.keys():\n",
    "        word, _ = key\n",
    "        pos_neg_ratio = get_ratio(freqs, word)\n",
    "\n",
    "        if label == 1 and pos_neg_ratio[\"ratio\"] > threshold:\n",
    "            word_set[word] = pos_neg_ratio\n",
    "        elif label == 0 and pos_neg_ratio[\"ratio\"] <= threshold:\n",
    "            word_set[word] = pos_neg_ratio\n",
    "\n",
    "    return word_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{':(': {'positive': 1, 'negative': 3675, 'ratio': 0.000544069640914037},\n",
       " ':-(': {'positive': 0, 'negative': 386, 'ratio': 0.002583979328165375},\n",
       " 'zayniscomingbackonjuli': {'positive': 0, 'negative': 19, 'ratio': 0.05},\n",
       " '26': {'positive': 0, 'negative': 20, 'ratio': 0.047619047619047616},\n",
       " '>:(': {'positive': 0, 'negative': 43, 'ratio': 0.022727272727272728},\n",
       " 'lost': {'positive': 0, 'negative': 19, 'ratio': 0.05},\n",
       " '♛': {'positive': 0, 'negative': 210, 'ratio': 0.004739336492890996},\n",
       " '》': {'positive': 0, 'negative': 210, 'ratio': 0.004739336492890996},\n",
       " 'beli̇ev': {'positive': 0, 'negative': 35, 'ratio': 0.027777777777777776},\n",
       " 'wi̇ll': {'positive': 0, 'negative': 35, 'ratio': 0.027777777777777776},\n",
       " 'justi̇n': {'positive': 0, 'negative': 35, 'ratio': 0.027777777777777776},\n",
       " 'ｓｅｅ': {'positive': 0, 'negative': 35, 'ratio': 0.027777777777777776},\n",
       " 'ｍｅ': {'positive': 0, 'negative': 35, 'ratio': 0.027777777777777776}}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your function: find negative words at or below a threshold\n",
    "get_words_by_threshold(freqs, label=0, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'followfriday': {'positive': 23, 'negative': 0, 'ratio': 24.0},\n",
       " 'commun': {'positive': 27, 'negative': 1, 'ratio': 14.0},\n",
       " ':)': {'positive': 2960, 'negative': 2, 'ratio': 987.0},\n",
       " 'flipkartfashionfriday': {'positive': 16, 'negative': 0, 'ratio': 17.0},\n",
       " ':d': {'positive': 523, 'negative': 0, 'ratio': 524.0},\n",
       " ':p': {'positive': 105, 'negative': 0, 'ratio': 106.0},\n",
       " 'influenc': {'positive': 16, 'negative': 0, 'ratio': 17.0},\n",
       " ':-)': {'positive': 552, 'negative': 0, 'ratio': 553.0},\n",
       " \"here'\": {'positive': 20, 'negative': 0, 'ratio': 21.0},\n",
       " 'youth': {'positive': 14, 'negative': 0, 'ratio': 15.0},\n",
       " 'bam': {'positive': 44, 'negative': 0, 'ratio': 45.0},\n",
       " 'warsaw': {'positive': 44, 'negative': 0, 'ratio': 45.0},\n",
       " 'shout': {'positive': 11, 'negative': 0, 'ratio': 12.0},\n",
       " ';)': {'positive': 22, 'negative': 0, 'ratio': 23.0},\n",
       " 'stat': {'positive': 51, 'negative': 0, 'ratio': 52.0},\n",
       " 'arriv': {'positive': 57, 'negative': 4, 'ratio': 11.6},\n",
       " 'glad': {'positive': 41, 'negative': 2, 'ratio': 14.0},\n",
       " 'blog': {'positive': 27, 'negative': 0, 'ratio': 28.0},\n",
       " 'fav': {'positive': 11, 'negative': 0, 'ratio': 12.0},\n",
       " 'fback': {'positive': 26, 'negative': 0, 'ratio': 27.0},\n",
       " 'pleasur': {'positive': 10, 'negative': 0, 'ratio': 11.0}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your function; find positive words at or above a threshold\n",
    "get_words_by_threshold(freqs, label=1, threshold=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth Predicted Tweet\n",
      "1\t0.00\t@jaredNOTsubway @iluvmariah @Bravotv Then that truly is a LATERAL move! Now, we all know the Queen Bee is UPWARD BOUND : ) #MovingOnUp\n",
      "1\t0.00\ttruli later move know queen bee upward bound movingonup\n",
      "1\t0.00\tA new report talks about how we burn more calories in the cold, because we work harder to warm up. Feel any better about the weather? :p\n",
      "1\t0.00\tnew report talk burn calori cold work harder warm feel better weather :p\n",
      "1\t0.00\tHarry and niall and -94 (when harry was born) ik it's stupid and i wanna change it :D https://t.co/gHAt8ZDAfF\n",
      "1\t0.00\tharri niall 94 harri born ik stupid wanna chang :d\n",
      "1\t0.00\toff to the park to get some sunlight : )\n",
      "1\t0.00\tpark get sunlight\n",
      "1\t0.00\t@msarosh Uff Itna Miss karhy thy ap :p\n",
      "1\t0.00\tuff itna miss karhi thi ap :p\n",
      "0\t1.00\t@rcdlccom hello, any info about possible interest in Jonathas ?? He is close to join Betis :( greatings\n",
      "0\t1.00\thello info possibl interest jonatha close join beti :( great\n",
      "0\t1.00\t@phenomyoutube u probs had more fun with david than me : (\n",
      "0\t1.00\tu prob fun david\n",
      "0\t1.00\tpats jay : (\n",
      "0\t1.00\tpat jay\n",
      "0\t1.00\tSr. Financial Analyst - Expedia, Inc.: (#Bellevue, WA) http://t.co/ktknMhvwCI #Finance #ExpediaJobs #Job #Jobs #Hiring\n",
      "0\t1.00\tsr financi analyst expedia inc bellevu wa financ expediajob job job hire\n"
     ]
    }
   ],
   "source": [
    "# Some error analysis done for you\n",
    "print(\"Truth Predicted Tweet\")\n",
    "for x, y in zip(test_x, test_y):\n",
    "    y_hat = naive_bayes_predict(x, logprior, loglikelihood)\n",
    "    y_hat = 1 if y_hat > 0 else 0\n",
    "    if y != y_hat:\n",
    "        print(\"%d\\t%0.2f\\t%s\" % (y, y_hat, x))\n",
    "        print(\"%d\\t%0.2f\\t%s\" % (y, y_hat, \" \".join(process_tweet(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.603597049009226\n"
     ]
    }
   ],
   "source": [
    "# Test with your own tweet - feel free to modify `my_tweet`\n",
    "my_tweet = \"I am happy because I am learning :)\"\n",
    "\n",
    "p = naive_bayes_predict(my_tweet, logprior, loglikelihood)\n",
    "print(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
